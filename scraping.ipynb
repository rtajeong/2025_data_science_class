{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN0gYiq1gnjZqL5RRqaFB9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtajeong/2025_data_science_class/blob/main/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 크롤링 예제"
      ],
      "metadata": {
        "id": "6mBv03ZBzuRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def simple_crawler(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # http error 발생시 예외 발생\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    links = soup.find_all('a')   # 모든 <a> 태그(링크) 찾기\n",
        "\n",
        "    if links:\n",
        "        for link in links:\n",
        "            href = link.get('href')  # 링크의 'href' 속성 값 가져오기\n",
        "            if href:\n",
        "                print(href)\n",
        "\n",
        "start_url = \"https://www.google.com\" # 크롤링 시작 웹페이지 URL(예: 구글 홈)\n",
        "simple_crawler(start_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pylQtjmz1hyt",
        "outputId": "15839cd7-421b-43b7-fa2f-107492d8745c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.google.com/imghp?hl=en&tab=wi\n",
            "https://maps.google.com/maps?hl=en&tab=wl\n",
            "https://play.google.com/?hl=en&tab=w8\n",
            "https://www.youtube.com/?tab=w1\n",
            "https://news.google.com/?tab=wn\n",
            "https://mail.google.com/mail/?tab=wm\n",
            "https://drive.google.com/?tab=wo\n",
            "https://www.google.com/intl/en/about/products?tab=wh\n",
            "http://www.google.com/history/optout?hl=en\n",
            "/preferences?hl=en\n",
            "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=GAZAAQ\n",
            "/advanced_search?hl=en&authuser=0\n",
            "/intl/en/ads/\n",
            "/services/\n",
            "/intl/en/about.html\n",
            "/intl/en/policies/privacy/\n",
            "/intl/en/policies/terms/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  정적 페이지에서 명언 정보 추출"
      ],
      "metadata": {
        "id": "pTcqJEXiqe_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"http://quotes.toscrape.com/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "quotes = soup.select(\"div .quote\")  # class=\"quote\"\n",
        "print (f\"There are {len(quotes)} quotes on the page.\")\n",
        "\n",
        "for num, quote in enumerate(quotes, 1):\n",
        "    text = quote.select_one(\".text\").text\n",
        "    author = quote.select_one(\".author\").text\n",
        "    print(f\"{num}. {text} - {author}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAWCJgJNUSTJ",
        "outputId": "6c113fea-aabd-4687-a5c9-3fdd457d9662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10 quotes on the page.\n",
            "1. “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” - Albert Einstein\n",
            "2. “It is our choices, Harry, that show what we truly are, far more than our abilities.” - J.K. Rowling\n",
            "3. “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” - Albert Einstein\n",
            "4. “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” - Jane Austen\n",
            "5. “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” - Marilyn Monroe\n",
            "6. “Try not to become a man of success. Rather become a man of value.” - Albert Einstein\n",
            "7. “It is better to be hated for what you are than to be loved for what you are not.” - André Gide\n",
            "8. “I have not failed. I've just found 10,000 ways that won't work.” - Thomas A. Edison\n",
            "9. “A woman is like a tea bag; you never know how strong it is until it's in hot water.” - Eleanor Roosevelt\n",
            "10. “A day without sunshine is like, you know, night.” - Steve Martin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오픈 API (기상청 단기 예보)\n",
        "- 많은 공공기관 또는 민간 서비스는 오픈 API를 통해 구조화된 데이터를 제공한다. HTML을 분석하지 않아도 되므로 안정적이고 정확하게 원하는 정보를 얻을 수 있다는 장점이 있다. 특히 공공데이터 포털, 기상청, 뉴스, 금융 등의 분야에서 매우 유용하게 활용되고 있다.\n",
        "- 오픈 API는 일반 사용자에게 공개된 API로, 보통 인증키 발급을 통해 사용할 수 있다.\n",
        "- 대부분의 오픈 API는 JSON 또는 XML 형식으로 데이터를 제공한다."
      ],
      "metadata": {
        "id": "6KAzcUxBTsom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공공데이터 포털(https://www.data.go.kr) 에서 인증키 발급받기\n",
        "1. 공공데이터 포털 회원가입 및 로그인 후 인증키를 발급받는다.\n",
        "2. 원하는 공공데이터 검색 및 활용 신청\n",
        "   - 데이터 검색: 포털의 검색창을 통해 원하는 공공데이터를 검색한다. 예를 들어, \"날씨\", \"미세먼지\", \"버스\", \"지하철\" 등으로 검색\n",
        "   - 검색 결과 중 Open API 탭에서 원하는 데이터셋을 찾아 클릭.\n",
        "   - 선택한 API 상세 페이지에서 \"활용 신청\" 버튼을 클릭\n",
        "3. 인증키(Service Key) 발급 및 확인\n",
        "   - 활용 신청이 완료되면 마이페이지에서 \"API 키 발급/관리\" 또는 \"인증키 발급 현황\" 메뉴에서 발급된 인증키를 확인 가능\n",
        "   - 인증키는 일반적으로 인코딩된(Encoded) 버전과 디코딩된(Decoded) 버전이 제공되는데, API 호출 시 (특별히 지정되어 있지 않으면) 인코딩된 키를 주로 사용한다.\n",
        "4. API 명세 확인 및 테스트\n",
        "   - 각 Open API 상세 페이지에는 해당 API를 호출하는 데 필요한 요청 변수(Request Parameters), 응답 형식(Response Format), 샘플 URL 등이 됨.\n",
        "   - 샘플 URL 제공됨."
      ],
      "metadata": {
        "id": "5Znq-2KQ7Ttj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## params 딕셔너리를 이용한 API 호출\n",
        "- 이 방식은 API 요청의 파라미터들을 딕셔너리 형태로 관리하며 requests 라이브러리가 URL을 구성하게 하는 일반적인 방법 (키의 숨겨진 공백 문제를 해결하기 위해 my_key.strip()을 적용)\n",
        "- 특정 환경이나, 서비스 키 문자열에 눈에 보이지 않는 미세한 공백 또는 특수 문자가 포함되어 있을 경우, 파이썬 코드에서는 키가 유효하지 않다고 인식되어 SERVICE_KEY_IS_NOT_REGISTERED_ERROR 오류 메시지를 받을 수 있다.\n",
        "- (주의) 이 사이트는 하루 정보만을 제공하기 때문에 실행 전 날짜 정보 (base_date)를 고쳐 주어야 한다."
      ],
      "metadata": {
        "id": "skGZImOXjF-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# 1. API 호출 정보 설정\n",
        "# 주의: 복사-붙여넣기 시 앞뒤 공백이 포함되지 않도록 .strip()을 사용한다.\n",
        "my_key = \"UrcOXfOckvYo8hX%2F8AmlgQ8nIUSgSPH1u%2BuX7Z%2BkObecxxvDE8dHnkY3LQH2%2FPfOy8%2FM4LBA7dwd4eVpRTyQ4g%3D%3D\".strip()\n",
        "base_url = \"http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst\"\n",
        "\n",
        "# API 요청에 필요한 파라미터들을 딕셔너리 형태로 정의한다 (해당 사이트의 샘플 코드 참고)\n",
        "params = {\n",
        "    'serviceKey': my_key,\n",
        "    'pageNo': '1',\n",
        "    'numOfRows': '10',\n",
        "    'dataType': 'JSON',\n",
        "    'base_date': '20250710', # 예시 날짜 (API 명세에 맞는 형식)\n",
        "    'base_time': '0600',    # 예시 시간 (API 명세에 맞는 형식)\n",
        "    'nx': '55', # 예시 지점의 X좌표 (기상청 격자 좌표)\n",
        "    'ny': '127' # 예시 지점의 Y좌표 (기상청 격자 좌표)\n",
        "}\n",
        "\n",
        "# 2. API 요청 및 응답 처리\n",
        "# requests 라이브러리가 base_url과 params 딕셔너리를 조합하여 최종 URL을 구성하고 요청한다.\n",
        "response = requests.get(base_url, params=params)\n",
        "\n",
        "# 3. HTTP 상태 코드 확인 및 데이터 파싱\n",
        "if response.status_code == 200:\n",
        "    # 응답이 성공이면 파싱\n",
        "    json_data = response.json()\n",
        "    # 필요한 데이터는 'response' > 'body' > 'items' > 'item' 경로에 있다.\n",
        "    items = json_data['response']['body']['items']['item']\n",
        "    # Pandas DataFrame으로 변환하여 데이터를 표 형태로 정리한다.\n",
        "    df = pd.DataFrame(items)\n",
        "    print(\"API 호출 성공 및 DataFrame 생성 완료\")\n",
        "    print(df)\n",
        "else:\n",
        "    # 응답이 실패(200이 아님)한 경우 상태 코드를 출력한다.\n",
        "    print(f\"API 요청 실패: HTTP 상태 코드 {response.status_code}\")\n",
        "    print(f\"서버 응답 내용: \\n{response.text}\") # 실패 시 서버가 보낸 메시지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-paxEOjBqRTb",
        "outputId": "78d25ef1-e026-4810-9059-46a5553b8621",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 요청 실패: HTTP 상태 코드 404\n",
            "서버 응답 내용: \n",
            "<!DOCTYPE html>\n",
            "<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
            "<title>ìì¤í ì ê²</title>\n",
            "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
            "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\">\n",
            "<meta name=\"author\" content=\"êµ­ê°ì ë³´ììê´ë¦¬ì\">\n",
            "<!-- <link rel=\"shortcut icon\" href=\"/favicon.ico\"> -->\n",
            "<style>\n",
            "html,body { width:100%; height:100%; margin:0; padding:0; font-size:1em; line-height:1.5; color:#666; font-family: \"Noto Sans\", \"Malgun Gothic\", \"ë§ìê³ ë\", \"ëì\" }\n",
            ".wrapper { width:100%; height:100%; position:relative; }\n",
            "\n",
            "\n",
            ".PZwindow {\n",
            "\tborder:1px solid #ddd;\n",
            "\tbackground-color:#fff;\n",
            "    position:absolute;\n",
            "\t/*position:fixed !important;*/\n",
            "    z-index:99999;\n",
            "}\n",
            ".PZwindow * { \n",
            "\tfont-family: \"NotoKR\", \"Noto Sans\", \"Malgun Gothic\", \"ë§ìê³ ë\", \"ëì\" !important;\n",
            "\tfont-size:1em; \n",
            "\tline-height:1.5; \n",
            "\tcolor:#2e2e38;\n",
            "\tletter-spacing:-0.05em; \n",
            "}\n",
            ".PZwindow .PZwrap { \n",
            "\t/*min-width:373px; border-top:1px solid #ddd; border-right:1px solid #ddd; border-left:1px solid #ddd;*/\n",
            "\toverflow:hidden; \n",
            "}\n",
            ".PZwindow .nomoreOpen { border-right:1px solid #333; overflow:hidden; }\n",
            ".PZwindow .nomoreOpen form label { font-size:14px; color:#fff; }\n",
            ".PZwindow .nomoreOpen form a.PZwindowClose { margin-top:5px; }\n",
            ".reptxt,.longdesc { width:0; height:0; font-size:0; line-height:0; text-indent:-9999em; overflow:hidden; }\n",
            ".btn { padding:10px 20px; display:inline-block; font-weight:bold; color:#fff !important; text-decoration:none; background:url('/base/images/button_type_02.png') left top repeat; }\n",
            "\n",
            ".compop-wrap { \n",
            "\tmax-width:400px;\n",
            "\tbackground:url('/base/images/popup_background_img.jpg') top center no-repeat; \n",
            "\t/*min-height:calc(420px - 35px);*/\n",
            "\toverflow:hidden; \n",
            "}\n",
            ".compop-wrap .pop-head { margin:20px 0; text-align:center; overflow:hidden;  }\n",
            ".compop-wrap .pop-head h1 { font-size:1.2em; margin-bottom:10px; color:#666; font-weight:bold; }\n",
            ".compop-wrap .pop-head h1 span { padding-top:5px; display:block; color:#333; overflow:hidden; text-align:center; }\n",
            ".compop-wrap .pop-head .copytxt { font-size:1em; text-align:center; }\n",
            ".compop-wrap .pop-head .copytxt .bold { margin-bottom:10px; font-weight:bold; color:#333;font-size: 15px; }\n",
            ".compop-wrap .pop-head .copytxt span { border-bottom:1px solid #339; color:#339; font-weight:bold }\n",
            ".compop-wrap .pop-body { padding:0; overflow:hidden; }\n",
            ".compop-wrap .pop-body .pop-box { color:#fff; padding:0px 20px 0px 20px; font-size:0.87em; border-top-left-radius:5px; border-top-right-radius:5px;border-bottom-left-radius:5px; border-bottom-right-radius:5px; background:url('/base/images/popup_text_img.png') top center no-repeat; overflow:hidden; }\n",
            ".compop-wrap .pop-body .pop-box dl.list { margin-bottom:10px; list-style:none; overflow:hidden; position:relative; }\n",
            ".compop-wrap .pop-body .pop-box dl.list dt, .pop-body .pop-box dl.list dd { text-align:left; line-height:1.5; color:#fff; }\n",
            ".compop-wrap .pop-body .pop-box dl.list dt { width:30px; padding-left:9px; font-weight:bold; position:absolute; }\n",
            ".compop-wrap .pop-body .pop-box dl.list dt span { width:5px; height:2px; background-color:#fc0; position:absolute; top:10px; left:0; }\n",
            ".compop-wrap .pop-body .pop-box dl.list dd { width:calc(100% - 45px); margin-left:45px; padding-bottom:2px; }\n",
            ".compop-wrap .pop-body .pop-box dl.list dd span { color:#fc0; border-bottom:1px solid #fc0; font-weight:bold; }\n",
            ".compop-wrap .pop-body .pop-box p { margin-top:15px; font-size:12px; color:#ddd; position:relative; }\n",
            ".compop-wrap .pop-body .pop-box p::before { position:absolute; top:-1px; left:0; }\n",
            ".compop-wrap .pop-body .pop-box .pop-btn { text-align: center; }\n",
            "\n",
            "@media only screen and (min-width:768px) {\n",
            "\t.PZwindow {position:absolute; left:50%; top:50%; margin-top:-340px; margin-left:-245px;}\n",
            "\t.compop-wrap { min-width:calc(375px - 60px); /*max-width:calc(420px - 60px);*/ padding:10px 30px 0 30px; }\n",
            "}\n",
            "\n",
            "@media only screen and (max-width:737px) {\n",
            "\t.PZwindow { position:relative !important; left:0; top:0; }\n",
            "\t.compop-wrap { max-width:auto; padding:35px 10px 0 10px; }\n",
            "\t.compop-wrap .pop-body .pop-box { margin:0 15px; }\t\n",
            "}\n",
            "\n",
            ".lawpop-wrap { \n",
            "\tmax-width:490px;\n",
            "\tbackground:url('/base/images/popup_background_lawimg.png') top left no-repeat; \n",
            "\tmin-height:calc(420px - 35px);\n",
            "\toverflow:hidden; \n",
            "\t/*border:1px solid #ddd;*/\n",
            "}\n",
            ".lawpop-wrap .pop-head { min-height:140px; margin:10px 0; text-align:center; overflow:hidden;  }\n",
            ".lawpop-wrap .pop-head h1 { font-size:1.2em; color:#e7e7e7; font-weight:bold; }\n",
            ".lawpop-wrap .pop-head h1 span { padding-top:5px; display:block; color:#333; overflow:hidden; text-align:center; }\n",
            ".lawpop-wrap .pop-head .copytxt { font-size:1em; text-align:center; }\n",
            ".lawpop-wrap .pop-head .copytxt .bold { margin-bottom:10px; font-weight:bold; color:#333; }\n",
            ".lawpop-wrap .pop-head .copytxt span { border-bottom:1px solid #339; color:#339; font-weight:bold }\n",
            ".lawpop-wrap .pop-body { padding:0 25px; overflow:hidden; }\n",
            ".lawpop-wrap .pop-body ul.list { margin:0; padding:0; list-style:none; overflow:hidden; }\n",
            ".lawpop-wrap .pop-body ul.list li { margin-bottom:15px; padding:0 0 0 10px; font-size:13px; position:relative; text-align:justify; letter-spacing:-0.05em; }\n",
            ".lawpop-wrap .pop-body ul.list li::before { content:''; width:5px; height:2px; background-color:#930; position:absolute; top:6px; left:0; }\n",
            ".lawpop-wrap .pop-body ul.list li span { font-weight:bold; color:#fff; }\n",
            ".lawpop-wrap .pop-body ul.list ul.ul_2 { margin:5px 0 0 0; padding:0; list-style:none; overflow:hidden; }\n",
            ".lawpop-wrap .pop-body ul.list ul.ul_2 > li { padding:0 0 0 7px; }\n",
            ".lawpop-wrap .pop-body ul.list ul.ul_2 > li::before { content:''; width:3px; height:3px; background-color:#666; position:absolute; top:7px; left:0; }\n",
            ".lawpop-wrap .pop-body ul.list ul.ul_2 > li:last-child { margin:0 }\n",
            ".lawpop-wrap .pop-foot { padding:1em 0 2em 0; text-align:center; overflow:hidden; }\n",
            "\n",
            "/** ì ê·ëª¨ë°ì¼ì± **/\n",
            ".compop-wrap .app-store { list-style:none; overflow: hidden; }\n",
            ".compop-wrap .app-store li { float:left; width:50%; }\n",
            ".compop-wrap .app-store .btn-appDown { float:left; width:90px; height:130px; margin:0 auto; display:block; }\n",
            "\n",
            "/** ì´ë¯¸ì§ íì(ë¤ì´ë¡ë ë§í¬) **/\n",
            ".imgpop-wrap { \n",
            "\t/*width:375px;*/\n",
            "\tmin-height:420px;\n",
            "\tmargin:0 auto; \n",
            "\toverflow:hidden; \n",
            "}\n",
            ".imgpop-wrap .pop-body { padding:0; overflow:hidden; position:relative; }\n",
            ".imgpop-wrap .pop-body .pop-bg { position:relative; z-index:10; }\n",
            ".imgpop-wrap .pop-btn-down { width:265px; list-style:none; overflow:hidden; position:absolute; left:35px; bottom:10px; z-index:50; }\n",
            ".imgpop-wrap .pop-btn-down dd { float:left; width:33.3%; margin:0; padding:0; text-align:center; }\n",
            "</style>\n",
            "</head>\n",
            "\n",
            "<body>\n",
            "<div class=\"wrapper\">\n",
            "<div class=\"PZwindow\">\n",
            "<div class=\"PZwrap\">\n",
            "<div class=\"compop-wrap\"> \n",
            "<!-- <div id=\"logo\" style=\"padding-left:-20px; \"><img alt=\"logo\" src=\"/base/images/logo.png\" style=\"vertical-align: middle\">&nbsp;<b>ì¸êµë¶</b>&nbsp;&nbsp;&nbsp;</div> -->\n",
            "<div class=\"pop-head\">\n",
            "<div class=\"copytxt\"> \n",
            "<div id=\"logo\" style=\"padding-left:0px; \"><img alt=\"logo\" src=\"/base/images/logo.png\" height=\"16.5px\" style=\"vertical-align: middle\">&nbsp;<b style=\"vertical-align: middle\">íì ìì ë¶</b><br><br></div>\n",
            "<div id=\"logo\" style=\"font-size:20px; font-family: 'Malgun Gothic'\"><b>ìì¤í ì ê²</b></div>\n",
            "<p class=\"bold\">ìì¤í ì¥ì ë¡ ê³µê³µë°ì´í°í¬í¸ ìë¹ì¤ë¥¼ ì´ì©íì¤ ì ììµëë¤.<br />\r\n",
            "<br />\r\n",
            "íì¬ ì¥ì  ë³µêµ¬ ì¡°ì¹ ì¤ì´ë©° ë¹ ë¥¸ ìê° ë´ì ë³µêµ¬íëë¡ íê² ìµëë¤.<br />\r\n",
            "<br />\r\n",
            "ê³µê³µë°ì´í° ì ê³µ ëì²´ ì¬ì´í¸ë íë¨ì ë§í¬ë¥¼ í´ë¦­íì¬ íì¸í´ ì£¼ìê¸° ë°ëëë¤.<br />\r\n",
            "<br />\r\n",
            "ë§í¬ì£¼ì(NIA ê³µì§ì¬í­ ê²ìê¸)<br />\r\n",
            " - (<a href=\"https://www.nia.or.kr/site/nia_kor/ex/bbs/View.do?cbIdx=99835&bcIdx=28626&parentSeq=28626\">https://www.nia.or.kr/site/nia_kor/ex/bbs/View.do?cbIdx=99835&bcIdx=28626&parentSeq=28626</a>)</p> \n",
            "</div> </div> \n",
            "<div class=\"pop-body\"> \n",
            "<div class=\"pop-box\">\n",
            "<dl class=\"list\"> \n",
            "   <dt><span></span>ëì</dt> \n",
            "   <dd> <span>ì¤ìí API ëë©ì¸</span></dd>\n",
            "</dl> \n",
            "<dl class=\"list\"> \n",
            "  <dt><span></span>ì¼ì </dt> \n",
            "  <dd><span></span></dd> \n",
            "</dl>\n",
            "<p class=\"ps\"></p>\n",
            "</div> \n",
            "</div>\n",
            "\n",
            "\n",
            "<p class=\"bold\" style=\"text-align:right;font-size:12px; color:#333333;font-family: 'Malgun Gothic';vertical-align: middle\">&nbsp;</p>\n",
            "\n",
            "\n",
            " </div>\n",
            "</div>\n",
            "</div>\n",
            "</div>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## full_url을 이용한 API 호출\n",
        "- 브라우저에서 직접 테스트하여 완벽하게 작동하는 전체 URL 문자열을 직접 사용한다."
      ],
      "metadata": {
        "id": "EZV5_ZGwj6-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# 1. API 호출 정보 설정 (예시 날짜/시간 고정 :2025년7월10일 06:00 시)\n",
        "my_key = \"UrcOXfOckvYo8hX%2F8AmlgQ8nIUSgSPH1u%2BuX7Z%2BkObecxxvDE8dHnkY3LQH2%2FPfOy8%2FM4LBA7dwd4eVpRTyQ4g%3D%3D\".strip()\n",
        "base_url = \"http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst\"\n",
        "\n",
        "# 모든 파라미터가 포함된 완전한 URL\n",
        "full_api_url = base_url + \\\n",
        "    \"?serviceKey=\" + my_key + \\\n",
        "    \"&pageNo=1&numOfRows=10&dataType=JSON\" + \\\n",
        "    \"&base_date=20250711&base_time=0600\" + \\\n",
        "    \"&nx=55&ny=127\"\n",
        "\n",
        "# 2. API 요청 및 응답 처리\n",
        "response = requests.get(full_api_url)\n",
        "\n",
        "# 3. 상태 코드 확인 및 DataFrame으로 변환\n",
        "if response.status_code == 200:\n",
        "    json_data = response.json()\n",
        "    # 'response' -> 'body' -> 'items' -> 'item' 경로로 실제 데이터 접근\n",
        "    items = json_data['response']['body']['items']['item']\n",
        "    df = pd.DataFrame(items)\n",
        "    print(\"API 호출 성공 및 DataFrame 생성 완료 (full_url 방식):\")\n",
        "    print(df)\n",
        "else:\n",
        "    print(f\"API 요청 실패: HTTP 상태 코드 {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzwWlW6YnQjs",
        "outputId": "1b9f0bcf-7d46-4fbd-e9c5-39b662e0921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 요청 실패: HTTP 상태 코드 404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_data"
      ],
      "metadata": {
        "id": "VZxMV6Ugongj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 동적 스크래핑"
      ],
      "metadata": {
        "id": "YGdKJC2UEaLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## requests 라이브러리로 시도하기: 한계점"
      ],
      "metadata": {
        "id": "BLKLf1OKfH50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"http://quotes.toscrape.com/scroll\"\n",
        "\n",
        "response = requests.get(url)\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error: Failed to fetch the page. Status code: {response.status_code}\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all 'div' tags with the class 'quote'.\n",
        "# In this specific dynamic page's initial HTML, these might not be present.\n",
        "extracted_data = []\n",
        "quotes = soup.find_all('div', class_='quote')\n",
        "\n",
        "if quotes:\n",
        "    print(f\"Found {len(quotes)} quotes (requests - initial load):\")\n",
        "    for quote_div in quotes:\n",
        "        # Find the quote text (span tag with class='text') within each quote div.\n",
        "        text_element = quote_div.find('span', class_='text')\n",
        "        text = text_element.get_text(strip=True) if text_element else 'N/A'\n",
        "\n",
        "        # Find the author's name (small tag with class='author') within each quote div.\n",
        "        author_element = quote_div.find('small', class_='author')\n",
        "        author = author_element.get_text(strip=True) if author_element else 'N/A'\n",
        "\n",
        "        extracted_data.append({'Quote': text, 'Author': author})\n",
        "        print(f\"- {text[:50]}... (by {author})\") # Print example output\n",
        "else:\n",
        "    print(\"Error: Could not find quote elements (div class='quote') in the HTML.\")\n",
        "    print(\"This confirms the content is dynamically loaded by JavaScript.\")\n",
        "\n",
        "if extracted_data:\n",
        "    df_requests = pd.DataFrame(extracted_data)\n",
        "    print(\"\\nQuotes data fetched by requests (DataFrame, first 5 rows):\")\n",
        "    print(df_requests.head())\n",
        "    print(f\"\\nTotal quotes fetched by requests: {len(df_requests)}.\")\n",
        "else:\n",
        "    print(\"No data extracted by requests.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBYbaQnuo0yD",
        "outputId": "f4f75e7e-9b62-40ed-d882-24a5b0c145c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not find quote elements (div class='quote') in the HTML.\n",
            "This confirms the content is dynamically loaded by JavaScript.\n",
            "No data extracted by requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- request 가 실패하는 이유:\n",
        "  - 이 스크립트가 로드되는 최초 HTML(requests가 받아오는 내용)에는 <div class=\"quote\">와 같은 명언 태그가 거의 없다. (또는 아주 초기 몇 개만 있을 수 있다. quotes.toscrape.com/scroll의 경우, 이 스크립트가 첫 10개의 명언도 API로 가져와 append 한다. 즉, 'requests'가 받은 HTML에는 명언 태그가 하나도 없다.)\n",
        "  - requests는 단순히 response.text에 담긴 HTML 문자열과 JavaScript 코드 자체만 가져올 뿐이고, 브라우저처럼 이 JavaScript 코드를 실행시키지 않는다. 따라서 JavaScript가 API를 호출하고 HTML을 동적으로 생성하여 append하는 과정이 requests에게는 보이지 않는다.\n",
        "  - response.text에 script 코드가 보이고 명언 태그가 보이지 않는다는 것이 정확히 이 동적 페이지의 특징이며, requests의 한계를 명확하게 보여주는 증거이다."
      ],
      "metadata": {
        "id": "Sr79Cs9rlOol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네트워크 트래픽 분석을 통한 원본 데이터(API) 스크래핑"
      ],
      "metadata": {
        "id": "F-Ua2j6UEhLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Network tab analysis 를 통해 찾은 url: http://quotes.toscrape.com/api/quotes?page=1\n",
        "```"
      ],
      "metadata": {
        "id": "7d4ACI0mi9rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# The API URL discovered through network tab analysis\n",
        "# base_api_url = \"http://quotes.toscrape.com/api/quotes?page=1\"\n",
        "base_api_url = \"http://quotes.toscrape.com/api/quotes\"\n",
        "\n",
        "all_quotes_data_api = [] # List to store all fetched quote data\n",
        "page_num = 1             # Starting page number for the API\n",
        "\n",
        "while True:\n",
        "    print(f\"Fetching API page {page_num} data...\")\n",
        "    params = {\n",
        "        'page': page_num\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_api_url, params=params)\n",
        "\n",
        "    # Check if the HTTP status code is not 200 (OK).\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error during API request: Status code {response.status_code}\")\n",
        "        break # Exit loop if API request fails\n",
        "\n",
        "    json_data = response.json()\n",
        "\n",
        "    # Check the API response structure: quotes list is under the 'quotes' key\n",
        "    quotes_on_page = json_data.get('quotes', [])\n",
        "\n",
        "    if not quotes_on_page: # If no more quotes, break the loop\n",
        "        print(f\"No more quotes found on API page {page_num}. Ending crawl.\")\n",
        "        break\n",
        "\n",
        "    for quote_info in quotes_on_page:\n",
        "        quote_text = quote_info.get('text')\n",
        "        author_name = quote_info.get('author', {}).get('name')\n",
        "        all_quotes_data_api.append({'Quote': quote_text, 'Author': author_name})\n",
        "\n",
        "    page_num += 1 # Move to the next page\n",
        "\n",
        "print(f\"Total quotes fetched from API: {len(all_quotes_data_api)}\")\n",
        "\n",
        "if all_quotes_data_api:\n",
        "    df_api = pd.DataFrame(all_quotes_data_api)\n",
        "    print(\"\\nQuotes data fetched by direct API call (DataFrame, first 20 rows):\")\n",
        "    print(df_api.head(20))\n",
        "    print(f\"\\nTotal quotes fetched: {len(df_api)}.\")\n",
        "else:\n",
        "    print(\"No quotes data fetched from API.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhgYPegxEuCa",
        "outputId": "e4f77c41-6f56-4731-a80a-4b97cfd29ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching API page 1 data...\n",
            "Fetching API page 2 data...\n",
            "Fetching API page 3 data...\n",
            "Fetching API page 4 data...\n",
            "Fetching API page 5 data...\n",
            "Fetching API page 6 data...\n",
            "Fetching API page 7 data...\n",
            "Fetching API page 8 data...\n",
            "Fetching API page 9 data...\n",
            "Fetching API page 10 data...\n",
            "Fetching API page 11 data...\n",
            "No more quotes found on API page 11. Ending crawl.\n",
            "Total quotes fetched from API: 100\n",
            "\n",
            "Quotes data fetched by direct API call (DataFrame, first 20 rows):\n",
            "                                                Quote               Author\n",
            "0   “The world as we have created it is a process ...      Albert Einstein\n",
            "1   “It is our choices, Harry, that show what we t...         J.K. Rowling\n",
            "2   “There are only two ways to live your life. On...      Albert Einstein\n",
            "3   “The person, be it gentleman or lady, who has ...          Jane Austen\n",
            "4   “Imperfection is beauty, madness is genius and...       Marilyn Monroe\n",
            "5   “Try not to become a man of success. Rather be...      Albert Einstein\n",
            "6   “It is better to be hated for what you are tha...           André Gide\n",
            "7   “I have not failed. I've just found 10,000 way...     Thomas A. Edison\n",
            "8   “A woman is like a tea bag; you never know how...    Eleanor Roosevelt\n",
            "9   “A day without sunshine is like, you know, nig...         Steve Martin\n",
            "10  “This life is what you make it. No matter what...       Marilyn Monroe\n",
            "11  “It takes a great deal of bravery to stand up ...         J.K. Rowling\n",
            "12  “If you can't explain it to a six year old, yo...      Albert Einstein\n",
            "13  “You may not be her first, her last, or her on...           Bob Marley\n",
            "14  “I like nonsense, it wakes up the brain cells....            Dr. Seuss\n",
            "15  “I may not have gone where I intended to go, b...        Douglas Adams\n",
            "16  “The opposite of love is not hate, it's indiff...          Elie Wiesel\n",
            "17  “It is not a lack of love, but a lack of frien...  Friedrich Nietzsche\n",
            "18  “Good friends, good books, and a sleepy consci...           Mark Twain\n",
            "19  “Life is what happens to us while we are makin...       Allen Saunders\n",
            "\n",
            "Total quotes fetched: 100.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selenium in Colab\n",
        "- (1) a simple 예제"
      ],
      "metadata": {
        "id": "_ZWaHkmLEnat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selenium 및 필요한 라이브러리 설치\n",
        "!pip install selenium webdriver_manager beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "collapsed": true,
        "id": "J93QIK5x8UuP",
        "outputId": "fa9a6f92-3e0e-4060-8b97-5843ededf0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Collecting typing_extensions~=4.14.0 (from selenium)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (25.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver_manager) (3.4.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, typing_extensions, outcome, webdriver_manager, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 webdriver_manager-4.0.2 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing_extensions"
                ]
              },
              "id": "12acee25a04644038d22c27eb0cf7b41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "print(\"Selenium 기본 개념 예제 실행 준비 중...\")\n",
        "\n",
        "# --- 1. Chrome 옵션 설정 (Colab에서는 필수) ---\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")         # GUI 없이 백그라운드 실행\n",
        "chrome_options.add_argument(\"--no-sandbox\")       # Colab 환경 필수\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\") # 메모리 사용 최적화\n",
        "chrome_options.add_argument(\"--disable-gpu\")      # GPU 사용 비활성화\n",
        "chrome_options.add_argument(\"--window-size=1920,1080\") # 창 크기 설정\n",
        "chrome_options.add_argument(\"--incognito\")        # 시크릿 모드\n",
        "\n",
        "# --- 2. WebDriver 초기화 (ChromeDriverManager가 WebDriver를 알아서 찾아 설치) ---\n",
        "# Selenium 로봇 팔을 생성하고, 크롬 브라우저를 제어할 준비를 합니다.\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "print(\"WebDriver 초기화 완료. 브라우저가 실행되었습니다 (Headless 모드).\")\n",
        "\n",
        "# --- 3. 웹페이지 열기 ---\n",
        "# 로봇 팔에게 특정 URL로 이동하라고 명령합니다.\n",
        "url = \"https://www.naver.com\" # 간단한 예시로 네이버 사용\n",
        "print(f\"Opening webpage: {url}\")\n",
        "driver.get(url)\n",
        "\n",
        "# 페이지 로드를 위해 잠시 기다립니다. (필수는 아니지만 안정성을 위해)\n",
        "time.sleep(2)\n",
        "\n",
        "# --- 4. 현재 페이지의 HTML 소스 가져오기 ---\n",
        "# 로봇 팔이 현재 브라우저 화면에 보이는 HTML 전체를 복사해 옵니다.\n",
        "html_content = driver.page_source\n",
        "print(\"HTML content fetched.\")\n",
        "\n",
        "# --- 5. BeautifulSoup으로 HTML 파싱 및 데이터 추출 ---\n",
        "# 복사해 온 HTML을 BeautifulSoup으로 요리하여 원하는 정보를 찾습니다.\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# 웹페이지의 제목(title 태그)을 찾아봅니다.\n",
        "title_tag = soup.find('title')\n",
        "if title_tag:\n",
        "    page_title = title_tag.get_text(strip=True)\n",
        "    print(f\"Page Title: {page_title}\")\n",
        "else:\n",
        "    print(\"Page title not found.\")\n",
        "\n",
        "# --- 6. 브라우저 닫기 ---\n",
        "# 모든 작업이 끝나면, 로봇 팔에게 브라우저를 닫으라고 명령합니다.\n",
        "# 이 과정을 잊으면 백그라운드에서 브라우저가 계속 실행되어 컴퓨터 자원을 소모합니다.\n",
        "driver.quit()\n",
        "print(\"Browser closed. Selenium session ended.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "ZtinmH1v90-Q",
        "outputId": "63078b39-d52a-438f-9662-03678e8fd595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selenium 기본 개념 예제 실행 준비 중...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5ae51be284e3 <unknown>\n#1 0x5ae51bb57c76 <unknown>\n#2 0x5ae51bb7e757 <unknown>\n#3 0x5ae51bb7d029 <unknown>\n#4 0x5ae51bbbbccc <unknown>\n#5 0x5ae51bbbb47f <unknown>\n#6 0x5ae51bbb2de3 <unknown>\n#7 0x5ae51bb882dd <unknown>\n#8 0x5ae51bb8934e <unknown>\n#9 0x5ae51bde83e4 <unknown>\n#10 0x5ae51bdec3d7 <unknown>\n#11 0x5ae51bdf6b20 <unknown>\n#12 0x5ae51bded023 <unknown>\n#13 0x5ae51bdbb1aa <unknown>\n#14 0x5ae51be116b8 <unknown>\n#15 0x5ae51be11847 <unknown>\n#16 0x5ae51be21243 <unknown>\n#17 0x7e26d451aac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-208048881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Selenium 로봇 팔을 생성하고, 크롬 브라우저를 제어할 준비를 합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WebDriver 초기화 완료. 브라우저가 실행되었습니다 (Headless 모드).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fedcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5ae51be284e3 <unknown>\n#1 0x5ae51bb57c76 <unknown>\n#2 0x5ae51bb7e757 <unknown>\n#3 0x5ae51bb7d029 <unknown>\n#4 0x5ae51bbbbccc <unknown>\n#5 0x5ae51bbbb47f <unknown>\n#6 0x5ae51bbb2de3 <unknown>\n#7 0x5ae51bb882dd <unknown>\n#8 0x5ae51bb8934e <unknown>\n#9 0x5ae51bde83e4 <unknown>\n#10 0x5ae51bdec3d7 <unknown>\n#11 0x5ae51bdf6b20 <unknown>\n#12 0x5ae51bded023 <unknown>\n#13 0x5ae51bdbb1aa <unknown>\n#14 0x5ae51be116b8 <unknown>\n#15 0x5ae51be11847 <unknown>\n#16 0x5ae51be21243 <unknown>\n#17 0x7e26d451aac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 요약: Selenium의 동작 방식\n",
        "  - driver = webdriver.Chrome(...): \"크롬 브라우저를 제어할 로봇 팔을 준비해!\"\n",
        "  - driver.get(url): \"그 로봇 팔로 이 주소로 이동해!\"\n",
        "  - time.sleep(2): \"잠깐 기다려줘. 웹페이지가 다 로드되고 JavaScript도 실행될 시간을 줘.\" (더 정교한 대기 방법도 있지만, 초보자 예제에서는 time.sleep이 직관적입니다.)\n",
        "  - html_content = driver.page_source: \"지금 브라우저 화면에 보이는 모든 HTML 내용을 나에게 줘!\"\n",
        "  - soup = BeautifulSoup(html_content, 'html.parser'): \"받아온 HTML을 BeautifulSoup에게 넘겨줘서 쉽게 요리할 수 있게 해줘.\"\n",
        "  - driver.quit(): \"할 일 다 했으니 브라우저 닫고 로봇 팔 작업 끝내!\""
      ],
      "metadata": {
        "id": "3Axu1AU69H22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- (2) quotes.toscrape.com/scroll 예제 (generated by Gemini AI)\n",
        "  - http://quotes.toscrape.com/scroll 페이지를 스크롤하면서 각 스크롤 후 현재 페이지에 로드된 명언들 중 중복을 제외하고 수집하고, 최종적으로 수집된 명언들 중 첫 20개를 출력하는 코드이다.\n",
        "  - 이 코드는 무한 스크롤을 통해 새로운 명언이 더 이상 로드되지 않을 때까지 페이지를 계속 스크롤하며 데이터를 수집한다."
      ],
      "metadata": {
        "id": "9pNMPNTa9esl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selenium 및 필요한 라이브러리 설치\n",
        "!pip install selenium\n",
        "!pip install webdriver_manager\n",
        "!pip install beautifulsoup4 pandas"
      ],
      "metadata": {
        "id": "LZqKUy4LAK9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Selenium의 WebDriverWait 및 expected_conditions 임포트 (요소가 나타날 때까지 대기)\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By # By를 사용하여 요소를 찾습니다.\n",
        "\n",
        "print(\"Google Colab 환경에서 Selenium 설정 시작...\")\n",
        "\n",
        "# --- 1. Chrome 옵션 설정 (Headless 모드) ---\n",
        "# Selenium 로봇 팔이 사용할 브라우저의 특성을 정의합니다.\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")           # 브라우저 창을 띄우지 않고 백그라운드에서 실행\n",
        "chrome_options.add_argument(\"--no-sandbox\")         # Colab과 같은 리눅스 환경에서 필수적인 보안 설정 해제 (안전)\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\") # 메모리 사용을 최적화하여 오류 방지\n",
        "chrome_options.add_argument(\"--disable-gpu\")        # GPU 가속 비활성화\n",
        "chrome_options.add_argument(\"--window-size=1920,1080\") # 가상 브라우저 창의 크기 설정 (일관된 렌더링을 위해)\n",
        "chrome_options.add_argument(\"--incognito\")          # 시크릿 모드로 브라우저 시작\n",
        "\n",
        "# --- 2. WebDriver 초기화 ---\n",
        "# Selenium 로봇 팔을 생성하고, 크롬 브라우저를 제어할 준비를 합니다.\n",
        "# ChromeDriverManager().install()이 현재 크롬 버전에 맞는 WebDriver를 자동으로 다운로드하고 설정합니다.\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "print(\"Selenium WebDriver 초기화 완료. 브라우저가 실행되었습니다 (Headless 모드).\")\n",
        "\n",
        "url = \"http://quotes.toscrape.com/scroll\"\n",
        "all_unique_quotes_data = [] # 모든 고유한 명언 데이터를 저장할 리스트\n",
        "seen_quotes_set = set()      # 중복 명언을 추적하기 위한 집합(set)\n",
        "\n",
        "print(f\"\\n--- Scraping quotes from {url} using Selenium ---\")\n",
        "\n",
        "# --- 3. 웹페이지 열기 ---\n",
        "# 로봇 팔에게 특정 URL로 이동하라고 명령합니다.\n",
        "driver.get(url)\n",
        "print(f\"Accessed page: {url}\")\n",
        "\n",
        "# --- 4. 초기 페이지 로드 대기 ---\n",
        "# JavaScript에 의해 명언들이 동적으로 로드되므로, 최소한 하나의 명언 요소가 나타날 때까지 기다립니다.\n",
        "# 최대 15초까지 기다리며, 'quote' 클래스를 가진 요소가 DOM에 나타나면 다음 코드를 실행합니다.\n",
        "WebDriverWait(driver, 15).until(\n",
        "    EC.presence_of_element_located((By.CLASS_NAME, 'quote'))\n",
        ")\n",
        "print(\"Initial quotes loaded successfully. Starting infinite scroll and data collection...\")\n",
        "\n",
        "# --- 5. 무한 스크롤 및 데이터 수집 로직 ---\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\") # 현재 페이지의 스크롤 가능한 전체 높이\n",
        "scroll_count = 0\n",
        "\n",
        "while True:\n",
        "    scroll_count += 1\n",
        "    print(f\"Scrolling down... (Attempt {scroll_count})\")\n",
        "\n",
        "    # 페이지를 맨 아래로 스크롤하는 JavaScript 코드 실행\n",
        "    # 로봇 팔이 브라우저의 스크롤바를 맨 아래로 내리는 동작을 시뮬레이션합니다.\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    # 새로운 콘텐츠가 로드될 시간을 충분히 기다립니다. (네트워크 속도에 따라 조절)\n",
        "    # 이 시간 동안 브라우저는 JavaScript를 실행하고 API를 호출하여 명언들을 가져와 HTML에 추가합니다.\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 스크롤 후 새로운 높이 확인\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "    # --- 6. 현재 로드된 HTML에서 명언 추출 및 저장 ---\n",
        "    # 로봇 팔이 현재 브라우저 화면에 보이는 (JavaScript가 모두 실행되어 최종 렌더링된) HTML 전체를 복사해 옵니다.\n",
        "    html_content = driver.page_source\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # 'quote' 클래스를 가진 모든 div 태그 찾기\n",
        "    quotes_on_current_page = soup.find_all('div', class_='quote')\n",
        "\n",
        "    # 현재 페이지에서 찾은 명언들을 고유한 명언 리스트에 추가\n",
        "    for quote_div in quotes_on_current_page:\n",
        "        text_element = quote_div.find('span', class_='text')\n",
        "        author_element = quote_div.find('small', class_='author')\n",
        "\n",
        "        text = text_element.get_text(strip=True) if text_element else 'N/A'\n",
        "        author = author_element.get_text(strip=True) if author_element else 'N/A'\n",
        "\n",
        "        quote_tuple = (text, author) # 명언 텍스트와 저자를 튜플로 묶어 set에 저장 (set 은 중복 방지)\n",
        "        if quote_tuple not in seen_quotes_set: # 이전에 본 적 없는 명언이면 추가\n",
        "            all_unique_quotes_data.append({'Quote': text, 'Author': author})\n",
        "            seen_quotes_set.add(quote_tuple) # set에 추가하여 중복 방지\n",
        "\n",
        "    # --- 7. 더 이상 스크롤해도 높이가 변하지 않으면 반복 중지 ---\n",
        "    if new_height == last_height:\n",
        "        print(\"No more new content loaded after scrolling. All quotes are likely fetched.\")\n",
        "        break\n",
        "    last_height = new_height # 다음 스크롤을 위해 현재 높이를 저장\n",
        "\n",
        "print(f\"\\nTotal unique quotes collected: {len(all_unique_quotes_data)}.\")\n",
        "\n",
        "# --- 8. 수집된 명언을 DataFrame으로 변환 및 원하는 형식으로 출력 ---\n",
        "if all_unique_quotes_data:\n",
        "    df_quotes = pd.DataFrame(all_unique_quotes_data)\n",
        "\n",
        "    # 상위 20개의 명언만 선택합니다. (만약 20개 미만이면 모두 출력)\n",
        "    quotes_to_print = df_quotes.head(20)\n",
        "\n",
        "    print(\"\\n--- Collected Quotes (First 20): ---\")\n",
        "    # DataFrame을 요청하신 형식으로 출력합니다. (인덱스 포함, 전체 열 표시)\n",
        "    print(quotes_to_print)\n",
        "else:\n",
        "    print(\"No quotes were collected.\")\n",
        "\n",
        "# --- 9. WebDriver 종료 ---\n",
        "# 모든 작업이 끝나면, 로봇 팔에게 브라우저를 닫으라고 명령합니다.\n",
        "driver.quit()\n",
        "print(\"Selenium WebDriver closed. Task completed.\")"
      ],
      "metadata": {
        "id": "IUR3QzzmCb2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEQSkbkp-1PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dd80ba6",
        "outputId": "96ec1d2e-2730-4dea-bca2-a4d622088a87"
      },
      "source": [
        "# Install headless Chrome\n",
        "!apt-get update\n",
        "!apt install -y google-chrome-stable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [1\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [1\r                                                                               \rGet:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,006 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,264 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,581 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,794 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [88.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,627 kB]\n",
            "Fetched 30.0 MB in 3s (9,409 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package google-chrome-stable\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}